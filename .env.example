# Mindcore Environment Configuration
# Copy this file to .env and customize for your setup

# ===========================================
# Required: LLM Provider
# ===========================================
# OpenAI API Key (required unless using local llama.cpp)
OPENAI_API_KEY=sk-your-openai-api-key-here

# ===========================================
# Database Configuration
# ===========================================
POSTGRES_USER=mindcore_user
POSTGRES_PASSWORD=mindcore_pass
POSTGRES_DB=mindcore

# Direct PostgreSQL access (for admin/migrations only)
POSTGRES_DIRECT_PORT=5432

# ===========================================
# PgBouncer Connection Pooler
# ===========================================
# Similar to Supabase Pooler or Neon's connection pooling
PGBOUNCER_PORT=6432

# Pool mode: transaction (recommended), session, or statement
PGBOUNCER_POOL_MODE=transaction

# Maximum client connections (can handle 1000s of connections)
PGBOUNCER_MAX_CLIENT_CONN=1000

# Pool sizes
PGBOUNCER_DEFAULT_POOL_SIZE=25
PGBOUNCER_MIN_POOL_SIZE=5
PGBOUNCER_RESERVE_POOL_SIZE=5
PGBOUNCER_MAX_DB_CONNECTIONS=50

# Timeouts (seconds)
PGBOUNCER_SERVER_IDLE_TIMEOUT=600
PGBOUNCER_CLIENT_IDLE_TIMEOUT=0

# ===========================================
# API Server Configuration
# ===========================================
API_PORT=8000

# CORS origins (comma-separated, use * for all)
MINDCORE_CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# ===========================================
# Timezone Configuration
# ===========================================
# IANA timezone name (e.g., America/New_York, Europe/London, UTC)
MINDCORE_TIMEZONE=UTC

# ===========================================
# Logging
# ===========================================
LOG_LEVEL=INFO

# ===========================================
# Optional: Local LLM (llama.cpp)
# ===========================================
# Uncomment to use local LLM instead of OpenAI
# MINDCORE_LLM_PROVIDER=llama
# MINDCORE_LLAMA_MODEL_PATH=/models/your-model.gguf
